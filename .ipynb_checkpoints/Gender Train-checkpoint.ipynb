{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1aecf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3ca0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial parameters\n",
    "epochs = 100\n",
    "lr = 1e-3\n",
    "batch_size = 64\n",
    "img_dims = (96,96,3)\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# load image files from the dataset\n",
    "image_files = [f for f in glob.glob(r'# initial parameters\n",
    "epochs = 100\n",
    "lr = 1e-3\n",
    "batch_size = 64\n",
    "img_dims = (96,96,3)\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# load image files from the dataset\n",
    "image_files = [f for f in glob.glob(r'C:\\Users\\Shankar Karande\\Programming Languages\\Python AI & DS\\Gender Detection\\Gender-Detection-master\\gender_dataset_face' + \"/**/*\", recursive=True) if not os.path.isdir(f)]\n",
    "random.shuffle(image_files)\n",
    "\n",
    "# converting images to arrays and labelling the categories\n",
    "for img in image_files:\n",
    "\n",
    "    image = cv2.imread(img)\n",
    "    \n",
    "    image = cv2.resize(image, (img_dims[0],img_dims[1]))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "\n",
    "    label = img.split(os.path.sep)[-2] # C:\\Files\\gender_dataset_face\\woman\\face_1162.jpg\n",
    "    if label == \"woman\":\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "        \n",
    "    labels.append([label]) # [[1], [0], [0], ...]\n",
    "\n",
    "# pre-processing\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "# split dataset for training and validation\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.2,\n",
    "                                                  random_state=42)\n",
    "\n",
    "trainY = to_categorical(trainY, num_classes=2) # [[1, 0], [0, 1], [0, 1], ...]\n",
    "testY = to_categorical(testY, num_classes=2)\n",
    "\n",
    "# augmenting datset \n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "                         height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "                         horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# define model\n",
    "def build(width, height, depth, classes):\n",
    "    model = Sequential()\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\": #Returns a string, either 'channels_first' or 'channels_last'\n",
    "        inputShape = (depth, height, width)\n",
    "        chanDim = 1\n",
    "    \n",
    "    # The axis that should be normalized, after a Conv2D layer with data_format=\"channels_first\", \n",
    "    # set axis=1 in BatchNormalization.\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=inputShape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, (3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "\n",
    "    model.add(Conv2D(128, (3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(classes))\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "# build model\n",
    "model = build(width=img_dims[0], height=img_dims[1], depth=img_dims[2],\n",
    "                            classes=2)\n",
    "\n",
    "# compile the model\n",
    "opt = Adam(lr=lr, decay=lr/epochs)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# train the model\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=batch_size),\n",
    "                        validation_data=(testX,testY),\n",
    "                        steps_per_epoch=len(trainX) // batch_size,\n",
    "                        epochs=epochs, verbose=1)\n",
    "\n",
    "# save the model to disk\n",
    "model.save('gender_detection.model')\n",
    "\n",
    "# plot training/validation loss/accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = epochs\n",
    "plt.plot(np.arange(0,N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0,N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0,N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0,N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "# save plot to disk\n",
    "plt.savefig('plot.png')\\gender_dataset_face' + \"/**/*\", recursive=True) if not os.path.isdir(f)]\n",
    "random.shuffle(image_files)\n",
    "\n",
    "# converting images to arrays and labelling the categories\n",
    "for img in image_files:\n",
    "\n",
    "    image = cv2.imread(img)\n",
    "    \n",
    "    image = cv2.resize(image, (img_dims[0],img_dims[1]))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "\n",
    "    label = img.split(os.path.sep)[-2] # C:\\Files\\gender_dataset_face\\woman\\face_1162.jpg\n",
    "    if label == \"woman\":\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "        \n",
    "    labels.append([label]) # [[1], [0], [0], ...]\n",
    "\n",
    "# pre-processing\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "# split dataset for training and validation\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.2,\n",
    "                                                  random_state=42)\n",
    "\n",
    "trainY = to_categorical(trainY, num_classes=2) # [[1, 0], [0, 1], [0, 1], ...]\n",
    "testY = to_categorical(testY, num_classes=2)\n",
    "\n",
    "# augmenting datset \n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "                         height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "                         horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# define model\n",
    "def build(width, height, depth, classes):\n",
    "    model = Sequential()\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\": #Returns a string, either 'channels_first' or 'channels_last'\n",
    "        inputShape = (depth, height, width)\n",
    "        chanDim = 1\n",
    "    \n",
    "    # The axis that should be normalized, after a Conv2D layer with data_format=\"channels_first\", \n",
    "    # set axis=1 in BatchNormalization.\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=inputShape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, (3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "\n",
    "    model.add(Conv2D(128, (3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(classes))\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "# build model\n",
    "model = build(width=img_dims[0], height=img_dims[1], depth=img_dims[2],\n",
    "                            classes=2)\n",
    "\n",
    "# compile the model\n",
    "opt = Adam(lr=lr, decay=lr/epochs)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# train the model\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=batch_size),\n",
    "                        validation_data=(testX,testY),\n",
    "                        steps_per_epoch=len(trainX) // batch_size,\n",
    "                        epochs=epochs, verbose=1)\n",
    "\n",
    "# save the model to disk\n",
    "model.save('gender_detection.model')\n",
    "\n",
    "# plot training/validation loss/accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = epochs\n",
    "plt.plot(np.arange(0,N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0,N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0,N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0,N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "# save plot to disk\n",
    "plt.savefig('plot.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
